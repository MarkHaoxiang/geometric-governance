{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1755.71it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 299.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_scatter import scatter_max\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from geometric_governance.util import Logger, RangeOrValue, get_value\n",
    "from geometric_governance.data import (\n",
    "    generate_synthetic_election,\n",
    "    get_scoring_function_winners,\n",
    ")\n",
    "from geometric_governance.model import MessagePassingElectionModel, DeepSetStrategyModel\n",
    "\n",
    "device = torch.device(0) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"num_voters_range\": (3, 50),\n",
    "    \"num_candidates_range\": (2, 10),\n",
    "    \"train_dataset_size\": 1000,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"train_num_epochs\": 20,\n",
    "    \"eval_num_voters\": 75,\n",
    "    \"eval_num_candidates\": 15,\n",
    "    \"eval_dataset_size\": 1_000,\n",
    "    \"welfare_fn\": \"nash\",\n",
    "    \"top_k_candidates\": None,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"use_welfare_loss\": True,\n",
    "    \"use_monotonicity_loss\": True,\n",
    "    \"monotonicity_loss_batch_size\": 32,\n",
    "    \"strategy_loss_batch_size\": 64,\n",
    "}\n",
    "\n",
    "\n",
    "def generate_welfare_bipartite_dataset(\n",
    "    dataset_size: int,\n",
    "    num_voters_range: RangeOrValue,\n",
    "    num_candidates_range: RangeOrValue,\n",
    "    dataloader_batch_size: int,\n",
    "    top_k_candidates: int,\n",
    "    welfare_fn: Literal[\"utilitarian\", \"nash\", \"rawlsian\"],\n",
    "    rng: np.random.Generator,\n",
    "):\n",
    "    graphs = []\n",
    "    for _ in tqdm(range(dataset_size)):\n",
    "        num_voters = get_value(num_voters_range, rng)\n",
    "        num_candidates = get_value(num_candidates_range, rng)\n",
    "\n",
    "        election_data = generate_synthetic_election(\n",
    "            num_voters=num_voters, num_candidates=num_candidates, rng=rng\n",
    "        )\n",
    "\n",
    "        graph = election_data.to_bipartite_graph(top_k_candidates, vote_data=\"ranking\")\n",
    "\n",
    "        candidate_welfare = election_data.voter_utilities\n",
    "        match welfare_fn:\n",
    "            case \"utilitarian\":\n",
    "                candidate_welfare = election_data.voter_utilities.sum(dim=0)\n",
    "            case \"nash\":\n",
    "                #print(election_data.voter_utilities[:, 0])\n",
    "                log_voter_utilities = torch.log(election_data.voter_utilities)\n",
    "                #print(log_voter_utilities[:, 0])\n",
    "                candidate_welfare = log_voter_utilities.sum(dim=0)\n",
    "                #print(candidate_welfare[0])\n",
    "            case \"rawlsian\":\n",
    "                candidate_welfare = election_data.voter_utilities.min(dim=0)[0]\n",
    "            case _:\n",
    "                raise ValueError(\"Unknown welfare function.\")\n",
    "\n",
    "        winners = get_scoring_function_winners(candidate_welfare)\n",
    "\n",
    "        graph.y = candidate_welfare\n",
    "        graph.winners = winners\n",
    "        graphs.append(graph)\n",
    "    dataloader = DataLoader(graphs, batch_size=dataloader_batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "train_dataloader = generate_welfare_bipartite_dataset(\n",
    "    dataset_size=config[\"train_dataset_size\"],\n",
    "    num_voters_range=config[\"num_voters_range\"],\n",
    "    num_candidates_range=config[\"num_candidates_range\"],\n",
    "    dataloader_batch_size=config[\"train_batch_size\"],\n",
    "    top_k_candidates=config[\"top_k_candidates\"],\n",
    "    welfare_fn=config[\"welfare_fn\"],\n",
    "    rng=np.random.default_rng(seed=42),\n",
    ")\n",
    "\n",
    "eval_dataloader = generate_welfare_bipartite_dataset(\n",
    "    dataset_size=config[\"eval_dataset_size\"],\n",
    "    num_voters_range=config[\"eval_num_voters\"],\n",
    "    num_candidates_range=config[\"eval_num_candidates\"],\n",
    "    dataloader_batch_size=config[\"train_batch_size\"],\n",
    "    top_k_candidates=config[\"top_k_candidates\"],\n",
    "    welfare_fn=config[\"welfare_fn\"],\n",
    "    rng=np.random.default_rng(seed=16180),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 20/20 [16:43<00:00, 50.19s/it, train_strategy_loss=tensor(-37.8427, grad_fn=<AddBackward0>), train_welfare_loss=0, train_monotonicity_loss=0, train_welfare=0, eval_loss=-0.605, ev\n"
     ]
    }
   ],
   "source": [
    "edge_dim = 1\n",
    "\n",
    "strategy_model = DeepSetStrategyModel(edge_dim=edge_dim, emb_dim=32)\n",
    "election_model = MessagePassingElectionModel(edge_dim=edge_dim)\n",
    "election_model.load_state_dict(torch.load(\"election_model\", weights_only=True))\n",
    "\n",
    "strategy_model.to(device=device)\n",
    "election_model.to(device=device)\n",
    "\n",
    "s_optim = torch.optim.Adam(strategy_model.parameters(), lr=config[\"learning_rate\"])\n",
    "e_optim = torch.optim.Adam(election_model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "experiment_name = \"robust-voting\"\n",
    "logger = Logger(\n",
    "    experiment_name=experiment_name,\n",
    "    config=config,\n",
    "    mode=\"online\",\n",
    ")\n",
    "\n",
    "with tqdm(range(config[\"train_num_epochs\"])) as pbar:\n",
    "    for epoch in range(config[\"train_num_epochs\"]):\n",
    "        # Train\n",
    "        train_loss = 0\n",
    "        train_welfare_loss = 0\n",
    "        train_monotonicity_loss = 0\n",
    "        train_welfare = 0\n",
    "\n",
    "        election_model.train()\n",
    "        for data_ in train_dataloader:\n",
    "            data = data_.to(device=device)\n",
    "\n",
    "            # Train strategy model\n",
    "            strategic_votes = strategy_model(\n",
    "                data.edge_attr, data.edge_index, data.candidate_idxs\n",
    "            )\n",
    "\n",
    "            strategy_loss = 0\n",
    "\n",
    "            voters = (~data.candidate_idxs).nonzero()\n",
    "            candidates_to_batch = data.batch[data.candidate_idxs.nonzero()]\n",
    "\n",
    "            perm = torch.randperm(voters.size(0))[: config[\"strategy_loss_batch_size\"]]\n",
    "            for i in perm:\n",
    "                # TODO: We can vectorise this by picking one random vote from each batch\n",
    "                voter_idx = voters[i].item()\n",
    "                batch = data.batch[voter_idx]\n",
    "\n",
    "                voter_edge_attr_index = data.edge_index[0] == voter_idx\n",
    "\n",
    "                gradient_mask = torch.ones(data.edge_attr.shape[0], device=device)\n",
    "                gradient_mask[voter_edge_attr_index] = 0\n",
    "                gradient_mask = gradient_mask.bool()\n",
    "                gradient_mask = gradient_mask.unsqueeze(-1)\n",
    "\n",
    "                # Pass through frozen election model\n",
    "                gradient_cut_strategic_votes = torch.where(\n",
    "                    gradient_mask, strategic_votes.detach(), strategic_votes\n",
    "                )\n",
    "                data_strategy = data.clone()\n",
    "                data_strategy.edge_attr = strategic_votes\n",
    "                out = election_model(data_strategy)[\n",
    "                    (candidates_to_batch == batch).squeeze()\n",
    "                ]\n",
    "\n",
    "                # Calculate loss\n",
    "                vote_probabilities = torch.exp(out)\n",
    "                voter_welfare = data.edge_attr[voter_edge_attr_index].squeeze()\n",
    "\n",
    "                loss = -(vote_probabilities * voter_welfare).sum()\n",
    "                strategy_loss += loss\n",
    "\n",
    "            strategy_loss.backward()\n",
    "            s_optim.step()\n",
    "\n",
    "            logger.log({\n",
    "                \"train/strategy_loss\": strategy_loss,\n",
    "            })\n",
    "\n",
    "            ##########################\n",
    "\n",
    "        #     # Train election model\n",
    "        #     e_optim.zero_grad()\n",
    "\n",
    "        #     with torch.no_grad():\n",
    "        #         # strategic_votes = strategy_model(\n",
    "        #         #     data.edge_attr, data.edge_index, data.candidate_idxs\n",
    "        #         # )\n",
    "        #         strategic_votes = data.edge_attr\n",
    "        #     data.edge_attr = strategic_votes\n",
    "        #     data.edge_attr.requires_grad = True\n",
    "        #     out = election_model(data)\n",
    "\n",
    "        #     if config[\"use_welfare_loss\"]:\n",
    "        #         welfare_loss = (\n",
    "        #             -(torch.exp(out) * data.y).sum() / config[\"train_batch_size\"]\n",
    "        #         )\n",
    "        #     else:\n",
    "        #         welfare_loss = -(out * data.winners).sum() / config[\"train_batch_size\"]\n",
    "\n",
    "        #     # Monotonicity loss\n",
    "        #     monotonicity_loss = 0\n",
    "\n",
    "        #     if config[\"use_monotonicity_loss\"]:\n",
    "        #         candidates = data.candidate_idxs.nonzero()\n",
    "        #         perm = torch.randperm(candidates.size(0))[\n",
    "        #             : config[\"monotonicity_loss_batch_size\"]\n",
    "        #         ]\n",
    "        #         for i in perm:\n",
    "        #             candidate_idx = candidates[i]\n",
    "        #             edge_idxs = data.edge_index[1] == candidate_idx\n",
    "        #             grad = torch.autograd.grad(\n",
    "        #                 outputs=out[i], inputs=data.edge_attr, create_graph=True\n",
    "        #             )[0]\n",
    "        #             monotonicity_loss += torch.where(\n",
    "        #                 grad[edge_idxs] < 0,\n",
    "        #                 -grad[edge_idxs],\n",
    "        #                 torch.zeros_like(grad[edge_idxs]),\n",
    "        #             ).mean()\n",
    "        #     monotonicity_loss /= config[\"monotonicity_loss_batch_size\"]\n",
    "\n",
    "        #     loss = welfare_loss + monotonicity_loss\n",
    "        #     loss.backward()\n",
    "        #     e_optim.step()\n",
    "\n",
    "        #     batch_idxs = data.batch[data.candidate_idxs]\n",
    "        #     _, predicted = scatter_max(out, batch_idxs)\n",
    "        #     welfare = data.y[predicted].mean()\n",
    "        #     train_welfare += welfare.item()\n",
    "\n",
    "        #     train_loss += loss.item()\n",
    "        #     train_welfare_loss += welfare_loss.item()\n",
    "        #     if config[\"use_monotonicity_loss\"]:\n",
    "        #         train_monotonicity_loss += monotonicity_loss.item()\n",
    "\n",
    "        # train_loss /= len(train_dataloader)\n",
    "        # train_welfare_loss /= len(train_dataloader)\n",
    "        # train_monotonicity_loss /= len(train_dataloader)\n",
    "        # train_welfare /= len(train_dataloader)\n",
    "\n",
    "        # logger.log(\n",
    "        #     {\n",
    "        #         \"train/total_loss\": train_loss,\n",
    "        #         \"train/welfare_loss\": train_welfare_loss,\n",
    "        #         \"train/monotonicity_loss\": train_monotonicity_loss,\n",
    "        #         \"train/welfare\": train_welfare,\n",
    "        #     }\n",
    "        # )\n",
    "\n",
    "        # Eval\n",
    "        election_model.eval()\n",
    "        eval_loss = 0\n",
    "        eval_welfare = 0\n",
    "        total, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data_ in eval_dataloader:\n",
    "                data = data_.to(device=device)\n",
    "                out = election_model(data)\n",
    "                if config[\"use_welfare_loss\"]:\n",
    "                    welfare_loss = (\n",
    "                        -(torch.exp(out) * data.y).sum() / config[\"train_batch_size\"]\n",
    "                    )\n",
    "                else:\n",
    "                    welfare_loss = (\n",
    "                        -(out * data.winners).sum() / config[\"train_batch_size\"]\n",
    "                    )\n",
    "                batch_idxs = data.batch[data.candidate_idxs]\n",
    "                _, predicted = scatter_max(out, batch_idxs)\n",
    "                _, predicted_ground = scatter_max(data.y, batch_idxs)\n",
    "                total += predicted_ground.shape[0]\n",
    "                correct += (predicted == predicted_ground).sum().item()\n",
    "\n",
    "                welfare = data.y[predicted].mean()\n",
    "                eval_loss += loss.item()\n",
    "                eval_welfare += welfare.item()\n",
    "\n",
    "        eval_loss /= len(eval_dataloader)\n",
    "        eval_welfare /= len(eval_dataloader)\n",
    "        eval_accuracy = correct / total\n",
    "        logger.log(\n",
    "            {\n",
    "                \"eval/loss\": eval_loss,\n",
    "                \"eval/accuracy\": eval_accuracy,\n",
    "                \"eval/welfare\": eval_welfare,\n",
    "            }\n",
    "        )\n",
    "        logger.commit()\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            {\n",
    "                \"train_strategy_loss\": strategy_loss,\n",
    "                \"train_welfare_loss\": train_welfare_loss,\n",
    "                \"train_monotonicity_loss\": train_monotonicity_loss,\n",
    "                \"train_welfare\": train_welfare,\n",
    "                \"eval_loss\": eval_loss,\n",
    "                \"eval_accuracy\": eval_accuracy,\n",
    "                \"eval_welfare\": eval_welfare,\n",
    "            }\n",
    "        )\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MessagePassingElectionModel(\n",
       "  (lin_in_node): Linear(in_features=2, out_features=32, bias=True)\n",
       "  (lin_out_node): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (lin_in_edge): Linear(in_features=1, out_features=8, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0-3): 4 x MessagePassingElectionLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy_model.eval()\n",
    "election_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[11520, 2], edge_index=[2, 144000], edge_attr=[144000, 1], candidate_idxs=[11520], y=[1920], winners=[1920], batch=[11520], ptr=[129])\n",
      "tensor([[1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667]])\n",
      "tensor([-244.3496, -244.4295, -251.2200, -234.9458, -256.2701, -245.3695,\n",
      "        -247.3620, -254.4978, -246.3366, -223.2773, -224.2537, -235.8987,\n",
      "        -250.9261, -251.4386, -247.4723, -250.8666, -248.5307, -256.0498,\n",
      "        -269.7926, -252.2367, -239.8211, -226.2434, -243.0133, -240.1358,\n",
      "        -248.8315, -227.7047, -235.1521, -229.7687, -220.0310, -234.4682,\n",
      "        -243.2403, -265.5081, -253.7536, -252.0398, -241.5380, -256.7200,\n",
      "        -244.9679, -238.7455, -222.3213, -231.6751, -239.5397, -249.4520,\n",
      "        -235.1748, -214.4036, -260.5120, -233.9676, -240.7783, -249.8251,\n",
      "        -255.3930, -244.8076, -239.6165, -264.3188, -240.2755, -253.8972,\n",
      "        -242.7646, -237.1074, -249.5555, -242.1565, -237.8795, -225.8764,\n",
      "        -245.8816, -240.0940, -239.4393, -244.2796, -247.9760, -254.9926,\n",
      "        -240.0486, -238.0438, -241.6348, -253.8899, -252.3923, -235.7970,\n",
      "        -235.2753, -217.0657, -255.1469, -239.7065, -241.1206, -252.0694,\n",
      "        -242.6845, -234.8877, -240.2785, -233.6372, -244.7402, -247.2841,\n",
      "        -239.4589, -225.7819, -249.3952, -229.6078, -251.7616, -265.5381])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([-2.1443e+02, -2.8683e+02, -2.8825e+02, -1.3429e+02, -2.8658e+02,\n",
      "        -3.4395e+02, -2.6048e+02, -3.6450e+02, -2.9631e+02,  0.0000e+00,\n",
      "        -2.0103e+01, -1.2195e+02, -3.0940e+02, -2.5378e+02, -3.5337e+02,\n",
      "        -2.9885e+02, -2.8884e+02, -3.3672e+02, -5.5125e+02, -4.0225e+02,\n",
      "        -1.4489e+02, -8.0164e+01, -2.8683e+02, -2.1445e+02, -3.3540e+02,\n",
      "        -7.1526e-07, -1.5223e+02, -7.0323e+01, -1.4136e+01, -2.1326e+02,\n",
      "        -3.2345e+02, -6.5005e+02, -4.4746e+02, -4.2771e+02, -3.2841e+02,\n",
      "        -4.9995e+02, -3.6327e+02, -2.5539e+02, -9.2269e+01, -2.3991e+02,\n",
      "        -3.3977e+02, -4.2823e+02, -2.7492e+02,  0.0000e+00, -5.6743e+02,\n",
      "        -9.9878e+01, -1.4694e+02, -3.4623e+02, -2.8932e+02, -2.0553e+02,\n",
      "        -1.8161e+02, -4.0787e+02, -2.9195e+02, -3.5493e+02, -2.0030e+02,\n",
      "        -1.2699e+02, -2.7011e+02, -2.2150e+02, -1.5101e+02,  0.0000e+00,\n",
      "        -3.3175e+02, -4.3008e+02, -4.0804e+02, -4.2361e+02, -4.5765e+02,\n",
      "        -4.4937e+02, -3.0961e+02, -3.1853e+02, -2.9213e+02, -4.1412e+02,\n",
      "        -5.4296e+02, -3.5622e+02, -3.2642e+02,  0.0000e+00, -4.4662e+02,\n",
      "        -5.4258e+01, -2.0092e+02, -8.7854e+01, -1.6944e+02, -1.4050e+02,\n",
      "        -1.9485e-01, -1.9603e+01, -4.8746e+01, -2.0226e+02, -6.8677e+01,\n",
      "        -1.7314e+00, -1.9968e+02, -1.4889e+01, -2.2008e+02, -3.3701e+02],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "---\n",
      "tensor([  0.0000, -14.1360,   0.0000,   0.0000,   0.0000,  -1.7314],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "torch.Size([1920])\n"
     ]
    }
   ],
   "source": [
    "for data in islice(eval_dataloader, 1):\n",
    "    print(data)\n",
    "    print(data.edge_attr[:data.ptr[1]])\n",
    "    print(data.y[:data.ptr[1]])\n",
    "    print(data.winners[:data.ptr[1]])\n",
    "    out = election_model(data)\n",
    "    print(out[:data.ptr[1]])\n",
    "    print(\"---\")\n",
    "    print(out[:data.ptr[1]][data.winners[:data.ptr[1]].bool()])\n",
    "    print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[11520, 2], edge_index=[2, 144000], edge_attr=[144000, 1], candidate_idxs=[11520], y=[1920], winners=[1920], batch=[11520], ptr=[129])\n",
      "tensor([[1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667],\n",
      "        [1.0000],\n",
      "        [0.9333],\n",
      "        [0.8667],\n",
      "        [0.8000],\n",
      "        [0.7333],\n",
      "        [0.6667],\n",
      "        [0.6000],\n",
      "        [0.5333],\n",
      "        [0.4667],\n",
      "        [0.4000],\n",
      "        [0.3333],\n",
      "        [0.2667],\n",
      "        [0.2000],\n",
      "        [0.1333],\n",
      "        [0.0667]])\n",
      "tensor([-240.1964, -272.9848, -242.5562, -254.8016, -250.9774, -236.9054,\n",
      "        -233.8218, -234.9075, -232.1311, -247.8440, -247.5406, -233.8090,\n",
      "        -244.2287, -253.3808, -241.7042, -254.5425, -240.7886, -228.9120,\n",
      "        -242.3128, -258.7721, -246.7416, -257.5304, -252.9761, -255.5077,\n",
      "        -241.0993, -227.7050, -234.3589, -249.0105, -227.6785, -253.4556,\n",
      "        -233.6996, -249.7003, -232.8830, -235.9999, -246.2792, -254.9997,\n",
      "        -244.8927, -226.5052, -222.2602, -256.2888, -241.6641, -261.4608,\n",
      "        -244.4846, -252.7694, -254.0196, -234.9005, -245.2093, -223.0150,\n",
      "        -266.8613, -238.5883, -239.0046, -257.6816, -263.4700, -234.4618,\n",
      "        -236.1283, -236.2346, -262.6625, -233.8932, -252.4835, -233.1039,\n",
      "        -240.7337, -260.8150, -255.4706, -246.0054, -222.2205, -263.1871,\n",
      "        -253.4591, -265.6313, -245.6606, -236.6142, -236.6828, -231.2921,\n",
      "        -252.2029, -253.3301, -241.8022, -241.7731, -236.0756, -231.6619,\n",
      "        -246.5107, -239.8347, -239.4194, -241.6213, -254.7462, -244.4688,\n",
      "        -247.1045, -242.7463, -244.5399, -230.7850, -251.6618, -256.9188])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "---\n",
      "torch.Size([144000, 1])\n",
      "tensor([[1.8589],\n",
      "        [1.8667],\n",
      "        [1.8745],\n",
      "        [1.8823],\n",
      "        [1.8900],\n",
      "        [1.8978],\n",
      "        [1.9056],\n",
      "        [1.9134],\n",
      "        [1.9211],\n",
      "        [1.9289],\n",
      "        [1.9367],\n",
      "        [1.9445],\n",
      "        [1.9522],\n",
      "        [1.9600],\n",
      "        [1.9678],\n",
      "        [1.8589],\n",
      "        [1.8667],\n",
      "        [1.8745],\n",
      "        [1.8823],\n",
      "        [1.8900],\n",
      "        [1.8978],\n",
      "        [1.9056],\n",
      "        [1.9134],\n",
      "        [1.9211],\n",
      "        [1.9289],\n",
      "        [1.9367],\n",
      "        [1.9445],\n",
      "        [1.9522],\n",
      "        [1.9600],\n",
      "        [1.9678],\n",
      "        [1.8589],\n",
      "        [1.8667],\n",
      "        [1.8745],\n",
      "        [1.8823],\n",
      "        [1.8900],\n",
      "        [1.8978],\n",
      "        [1.9056],\n",
      "        [1.9134],\n",
      "        [1.9211],\n",
      "        [1.9289],\n",
      "        [1.9367],\n",
      "        [1.9445],\n",
      "        [1.9522],\n",
      "        [1.9600],\n",
      "        [1.9678],\n",
      "        [1.8589],\n",
      "        [1.8667],\n",
      "        [1.8745],\n",
      "        [1.8823],\n",
      "        [1.8900],\n",
      "        [1.8978],\n",
      "        [1.9056],\n",
      "        [1.9134],\n",
      "        [1.9211],\n",
      "        [1.9289],\n",
      "        [1.9367],\n",
      "        [1.9445],\n",
      "        [1.9522],\n",
      "        [1.9600],\n",
      "        [1.9678],\n",
      "        [1.8589],\n",
      "        [1.8667],\n",
      "        [1.8745],\n",
      "        [1.8823],\n",
      "        [1.8900],\n",
      "        [1.8978],\n",
      "        [1.9056],\n",
      "        [1.9134],\n",
      "        [1.9211],\n",
      "        [1.9289],\n",
      "        [1.9367],\n",
      "        [1.9445],\n",
      "        [1.9522],\n",
      "        [1.9600],\n",
      "        [1.9678],\n",
      "        [1.8589],\n",
      "        [1.8667],\n",
      "        [1.8745],\n",
      "        [1.8823],\n",
      "        [1.8900],\n",
      "        [1.8978],\n",
      "        [1.9056],\n",
      "        [1.9134],\n",
      "        [1.9211],\n",
      "        [1.9289],\n",
      "        [1.9367],\n",
      "        [1.9445],\n",
      "        [1.9522],\n",
      "        [1.9600],\n",
      "        [1.9678]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for data in islice(eval_dataloader, 1):\n",
    "    print(data)\n",
    "    print(data.edge_attr[:data.ptr[1]])\n",
    "    print(data.y[:data.ptr[1]])\n",
    "    print(data.winners[:data.ptr[1]])\n",
    "    print(data.candidate_idxs[:data.ptr[1]])\n",
    "    print(\"---\")\n",
    "    out = strategy_model(data.edge_attr, data.edge_index, data.candidate_idxs)\n",
    "    print(out.size())\n",
    "    print(out[:data.ptr[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(election_model.state_dict(), \"election_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
