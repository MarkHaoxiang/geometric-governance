{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader as TorchDataloader\n",
    "from torch_geometric.loader import DataLoader as GraphDataloader\n",
    "from torch_scatter import scatter_max\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from geometric_governance.util import (\n",
    "    Logger,\n",
    "    RangeOrValue,\n",
    "    get_value,\n",
    "    get_max,\n",
    "    OUTPUT_DIR,\n",
    ")\n",
    "from geometric_governance.data import (\n",
    "    SetDataset,\n",
    "    generate_synthetic_election,\n",
    "    get_scoring_function_winners,\n",
    ")\n",
    "from geometric_governance.model import (\n",
    "    MessagePassingElectionModel,\n",
    "    DeepSetElectionModel,\n",
    ")\n",
    "\n",
    "device = torch.device(0) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"num_voters_range\": (3, 50),\n",
    "    \"num_candidates_range\": (2, 10),\n",
    "    \"train_dataset_size\": 100_000,\n",
    "    # \"train_dataset_size\": 500_000,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"train_num_epochs\": 200,\n",
    "    \"checkpoint_interval\": 5,\n",
    "    \"val_num_voters\": 75,\n",
    "    \"val_num_candidates\": 15,\n",
    "    \"test_num_voters\": 100,\n",
    "    \"test_num_candidates\": 20,\n",
    "    # \"train_iterations_per_epoch\": 200,\n",
    "    \"train_iterations_per_epoch\": 100,\n",
    "    \"eval_dataset_size\": 1_000,\n",
    "    \"learning_rate\": 0.001,\n",
    "    # \"learning_rate\": 0.01,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"use_monotonicity_loss\": False,\n",
    "    \"monotonicity_loss_batch_size\": 32,\n",
    "    \"voting_rule\": \"copeland\",\n",
    "    \"representation\": \"graph\",\n",
    "}\n",
    "\n",
    "\n",
    "def generate_rule_dataset(\n",
    "    dataset_size: int,\n",
    "    num_voters_range: RangeOrValue,\n",
    "    num_candidates_range: RangeOrValue,\n",
    "    dataloader_batch_size: int,\n",
    "    top_k_candidates: int | None,\n",
    "    voting_rule: Literal[\"plurality\", \"borda\", \"copeland\"],\n",
    "    representation: Literal[\"set\", \"graph\"],\n",
    "    seed: int,\n",
    "    recompute: bool = True,\n",
    "):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    dataset_file = os.path.join(\n",
    "        OUTPUT_DIR,\n",
    "        f\"rule_dataset_{dataset_size}_{num_voters_range}_{num_candidates_range}_{representation}_{voting_rule}_{seed}.pt\",\n",
    "    )\n",
    "    if os.path.exists(dataset_file) and not recompute:\n",
    "        with open(dataset_file, \"rb\") as f:\n",
    "            dataset = torch.load(f, weights_only=False)\n",
    "    else:\n",
    "        dataset = []\n",
    "\n",
    "        generated_count = 0\n",
    "        with tqdm(range(dataset_size)) as pbar:\n",
    "            while generated_count < dataset_size:\n",
    "                num_voters = get_value(num_voters_range, rng)\n",
    "                num_candidates = get_value(num_candidates_range, rng)\n",
    "\n",
    "                election_data = generate_synthetic_election(\n",
    "                    num_voters=num_voters, num_candidates=num_candidates, rng=rng\n",
    "                )\n",
    "\n",
    "                match voting_rule:\n",
    "                    case \"plurality\":\n",
    "                        scores = election_data.positional_ballots[0]\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case \"borda\":\n",
    "                        scoring = torch.tensor(\n",
    "                            list(range(num_candidates, 0, -1)), dtype=torch.float32\n",
    "                        )\n",
    "                        scores = scoring @ election_data.positional_ballots\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case \"copeland\":\n",
    "                        scores = election_data.tournament_embedding.sum(dim=1)\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case _:\n",
    "                        raise ValueError(\"Unknown voting rule.\")\n",
    "\n",
    "                if winners.max() < 1.0:\n",
    "                    # Tie\n",
    "                    continue\n",
    "\n",
    "                if representation == \"graph\":\n",
    "                    graph = election_data.to_bipartite_graph(\n",
    "                        top_k_candidates, vote_data=\"ranking\"\n",
    "                    )\n",
    "                    graph.y = election_data.voter_utilities.sum(dim=0)\n",
    "                    graph.winners = winners\n",
    "                    dataset.append(graph)\n",
    "                elif representation == \"set\":\n",
    "                    pad_shape = get_max(num_candidates_range) - num_candidates\n",
    "                    voter_preferences = election_data.voter_preferences_alt\n",
    "                    voter_preferences = torch.nn.functional.pad(\n",
    "                        voter_preferences, (0, pad_shape, 0, 0)\n",
    "                    )\n",
    "                    winners = torch.nn.functional.pad(winners, (0, pad_shape))\n",
    "                    dataset.append((voter_preferences, winners))\n",
    "\n",
    "                generated_count += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "        with open(dataset_file, \"wb\") as f:\n",
    "            torch.save(dataset, f)\n",
    "\n",
    "    if representation == \"graph\":\n",
    "        dataloader = GraphDataloader(\n",
    "            dataset, batch_size=dataloader_batch_size, shuffle=True\n",
    "        )\n",
    "    elif representation == \"set\":\n",
    "        voter_preferences_list = [x[0] for x in dataset]\n",
    "        winner_list = [x[1] for x in dataset]\n",
    "        set_dataset = SetDataset(voter_preferences_list, winner_list)\n",
    "        dataloader = TorchDataloader(\n",
    "            set_dataset,\n",
    "            batch_size=dataloader_batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=SetDataset.collate_fn,\n",
    "        )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "generate_dataset = partial(\n",
    "    generate_rule_dataset,\n",
    "    voting_rule=config[\"voting_rule\"],\n",
    "    representation=config[\"representation\"],\n",
    "    dataloader_batch_size=config[\"train_batch_size\"],\n",
    "    top_k_candidates=None,\n",
    "    recompute=False,\n",
    ")\n",
    "\n",
    "train_dataloader = generate_dataset(\n",
    "    dataset_size=config[\"train_dataset_size\"],\n",
    "    num_voters_range=config[\"num_voters_range\"],\n",
    "    num_candidates_range=config[\"num_candidates_range\"],\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "val_dataloader = generate_dataset(\n",
    "    dataset_size=config[\"eval_dataset_size\"],\n",
    "    num_voters_range=config[\"val_num_voters\"],\n",
    "    num_candidates_range=config[\"val_num_candidates\"],\n",
    "    seed=16180,\n",
    ")\n",
    "\n",
    "if config[\"representation\"] == \"graph\":\n",
    "    test_num_candidates = config[\"test_num_candidates\"]\n",
    "elif config[\"representation\"] == \"set\":\n",
    "    test_num_candidates = get_max(config[\"num_candidates_range\"])\n",
    "\n",
    "test_dataloader = generate_dataset(\n",
    "    dataset_size=config[\"eval_dataset_size\"],\n",
    "    num_voters_range=config[\"test_num_voters\"],\n",
    "    num_candidates_range=test_num_candidates,\n",
    "    seed=314159,\n",
    ")\n",
    "\n",
    "config[\"train_iterations_per_epoch\"] = min(\n",
    "    config[\"train_iterations_per_epoch\"], len(iter(train_dataloader))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"representation\"] == \"graph\":\n",
    "    election_model = MessagePassingElectionModel(\n",
    "        node_emb_dim=256, edge_emb_dim=64, num_layers=4, edge_dim=1\n",
    "    )\n",
    "elif config[\"representation\"] == \"set\":\n",
    "    election_model = DeepSetElectionModel(\n",
    "        get_max(config[\"num_candidates_range\"]), embedding_size=155\n",
    "    )\n",
    "parameter_count = sum(p.numel() for p in election_model.parameters() if p.requires_grad)\n",
    "print(f\"parameter_count: {parameter_count}\")\n",
    "\n",
    "\n",
    "election_model.to(device=device)\n",
    "optim = torch.optim.Adam(election_model.parameters(), lr=config[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim, T_max=config[\"train_num_epochs\"], eta_min=1e-4\n",
    ")\n",
    "experiment_name = f\"{config['representation']}-election-{config['voting_rule']}\"\n",
    "with (\n",
    "    Logger(\n",
    "        experiment_name=experiment_name,\n",
    "        config=config,\n",
    "        mode=\"online\",\n",
    "    ) as logger,\n",
    "    tqdm(range(config[\"train_num_epochs\"])) as pbar,\n",
    "):\n",
    "    best_validation_accuracy: float = 0.0\n",
    "\n",
    "    for epoch in range(config[\"train_num_epochs\"]):\n",
    "        # Train\n",
    "        train_loss = 0\n",
    "        train_rule_loss = 0\n",
    "        train_monotonicity_loss = 0\n",
    "        train_welfare = 0\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        election_model.train()\n",
    "\n",
    "        train_iter = iter(train_dataloader)\n",
    "\n",
    "        for _ in range(config[\"train_iterations_per_epoch\"]):\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # Rule Loss\n",
    "            if config[\"representation\"] == \"graph\":\n",
    "                data = next(train_iter).to(device=device)\n",
    "                data.edge_attr.requires_grad = True\n",
    "                out = election_model(data)\n",
    "                winners = data.winners\n",
    "                rule_loss = -(out * winners).sum() / config[\"train_batch_size\"]\n",
    "            elif config[\"representation\"] == \"set\":\n",
    "                X, index, y = next(train_iter)\n",
    "                X = X.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "                index = index.to(device=device)\n",
    "                out = election_model(X, index=index)\n",
    "                winners = y\n",
    "                rule_loss = torch.nn.functional.cross_entropy(out, winners)\n",
    "\n",
    "            # Monotonicity loss\n",
    "            monotonicity_loss = 0\n",
    "\n",
    "            if config[\"use_monotonicity_loss\"] and config[\"representation\"] == \"graph\":\n",
    "                candidates = data.candidate_idxs.nonzero()\n",
    "                perm = torch.randperm(candidates.size(0))[\n",
    "                    : config[\"monotonicity_loss_batch_size\"]\n",
    "                ]\n",
    "                for i in perm:\n",
    "                    candidate_idx = candidates[i]\n",
    "                    edge_idxs = data.edge_index[1] == candidate_idx\n",
    "                    grad = torch.autograd.grad(\n",
    "                        outputs=out[i], inputs=data.edge_attr, create_graph=True\n",
    "                    )[0]\n",
    "                    monotonicity_loss += torch.where(\n",
    "                        grad[edge_idxs] < 0,\n",
    "                        -grad[edge_idxs],\n",
    "                        torch.zeros_like(grad[edge_idxs]),\n",
    "                    ).mean()\n",
    "            monotonicity_loss /= config[\"monotonicity_loss_batch_size\"]\n",
    "\n",
    "            loss = rule_loss + monotonicity_loss\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                election_model.parameters(), config[\"clip_grad_norm\"]\n",
    "            )\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if config[\"representation\"] == \"graph\":\n",
    "                batch_idxs = data.batch[data.candidate_idxs]\n",
    "                _, predicted = scatter_max(out, batch_idxs)\n",
    "                _, predicted_ground = scatter_max(winners, batch_idxs)\n",
    "            elif config[\"representation\"] == \"set\":\n",
    "                _, predicted = torch.max(out, dim=1)\n",
    "                _, predicted_ground = torch.max(winners, dim=1)\n",
    "\n",
    "            total += predicted_ground.shape[0]\n",
    "            correct += (predicted == predicted_ground).sum().item()\n",
    "            if config[\"representation\"] == \"graph\":\n",
    "                welfare = data.y[predicted].mean()\n",
    "                train_welfare += welfare.item()\n",
    "            train_loss += loss.item()\n",
    "            train_rule_loss += rule_loss.item()\n",
    "            if config[\"use_monotonicity_loss\"]:\n",
    "                train_monotonicity_loss += monotonicity_loss.item()\n",
    "\n",
    "        train_loss /= config[\"train_iterations_per_epoch\"]\n",
    "        train_rule_loss /= config[\"train_iterations_per_epoch\"]\n",
    "        train_monotonicity_loss /= config[\"train_iterations_per_epoch\"]\n",
    "        train_welfare /= config[\"train_iterations_per_epoch\"]\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        if epoch % config[\"checkpoint_interval\"] == 0:\n",
    "            torch.save(\n",
    "                election_model, os.path.join(logger.checkpoint_dir, f\"model_{epoch}.pt\")\n",
    "            )\n",
    "\n",
    "        logger.log(\n",
    "            {\n",
    "                \"train/total_loss\": train_loss,\n",
    "                \"train/rule_loss\": train_rule_loss,\n",
    "                \"train/monotonicity_loss\": train_monotonicity_loss,\n",
    "                \"train/welfare\": train_welfare,\n",
    "                \"train/accuracy\": train_accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        if config[\"representation\"] == \"graph\":\n",
    "            val_welfare = 0\n",
    "            election_model.eval()\n",
    "            total, correct = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for data_ in val_dataloader:\n",
    "                    data = data_.to(device=device)\n",
    "                    out = election_model(data)\n",
    "                    rule_loss = -(out * data.winners).sum() / config[\"train_batch_size\"]\n",
    "                    if config[\"representation\"] == \"graph\":\n",
    "                        batch_idxs = data.batch[data.candidate_idxs]\n",
    "                        _, predicted = scatter_max(out, batch_idxs)\n",
    "                        _, predicted_ground = scatter_max(data.winners, batch_idxs)\n",
    "                    elif config[\"representation\"] == \"set\":\n",
    "                        _, predicted = torch.max(out, dim=1)\n",
    "                        _, predicted_ground = torch.max(data.winners, dim=1)\n",
    "\n",
    "                    total += predicted_ground.shape[0]\n",
    "                    correct += (predicted == predicted_ground).sum().item()\n",
    "\n",
    "                    welfare = data.y[predicted].mean()\n",
    "                    val_loss += rule_loss.item()\n",
    "                    val_welfare += welfare.item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_welfare /= len(val_dataloader)\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "            if val_accuracy > best_validation_accuracy:\n",
    "                print(f\"New best accuracy: {val_accuracy}\")\n",
    "                torch.save(\n",
    "                    election_model,\n",
    "                    os.path.join(logger.checkpoint_dir, \"model_best.pt\"),\n",
    "                )\n",
    "                best_validation_accuracy = val_accuracy\n",
    "\n",
    "            logger.log(\n",
    "                {\n",
    "                    \"val/rule_loss\": val_loss,\n",
    "                    \"val/accuracy\": val_accuracy,\n",
    "                    \"val/welfare\": val_welfare,\n",
    "                }\n",
    "            )\n",
    "        logger.commit()\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            {\n",
    "                \"train_rule_loss\": train_rule_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_rule_loss\": val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "            }\n",
    "        )\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"representation\"] == \"graph\":\n",
    "    election_model = torch.load(\n",
    "        os.path.join(logger.checkpoint_dir, \"model_best.pt\"), weights_only=False\n",
    "    )\n",
    "    election_model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data_ in test_dataloader:\n",
    "            data = data_.to(device=device)\n",
    "            out = election_model(data)\n",
    "            rule_loss = -(out * data.winners).sum() / config[\"train_batch_size\"]\n",
    "            batch_idxs = data.batch[data.candidate_idxs]\n",
    "            _, predicted = scatter_max(out, batch_idxs)\n",
    "            _, predicted_ground = scatter_max(data.winners, batch_idxs)\n",
    "            total += predicted_ground.shape[0]\n",
    "            correct += (predicted == predicted_ground).sum().item()\n",
    "            test_loss += rule_loss.item()\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_accuracy = correct / total\n",
    "\n",
    "    print(f\"Test | Accuracy {test_accuracy} | Loss {test_loss}\")\n",
    "elif config[\"representation\"] == \"set\":\n",
    "    election_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, index, y in test_dataloader:\n",
    "            X = X.to(device)\n",
    "            index = index.to(device)\n",
    "            y = y.to(device)\n",
    "            p_y = election_model(X, index)\n",
    "            _, predicted = torch.max(p_y, dim=1)\n",
    "            _, predicted_ground = torch.max(y, dim=1)\n",
    "            total += y.shape[0]\n",
    "            correct += (predicted == predicted_ground).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
