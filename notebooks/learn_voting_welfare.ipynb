{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader as TorchDataloader\n",
    "from torch_geometric.loader import DataLoader as GraphDataloader\n",
    "from torch_scatter import scatter_max\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from geometric_governance.util import (\n",
    "    Logger,\n",
    "    RangeOrValue,\n",
    "    get_value,\n",
    "    get_max,\n",
    "    OUTPUT_DIR,\n",
    ")\n",
    "from geometric_governance.data import (\n",
    "    SetDataset,\n",
    "    generate_synthetic_election,\n",
    "    get_scoring_function_winners,\n",
    ")\n",
    "from geometric_governance.model import (\n",
    "    MessagePassingElectionModel,\n",
    "    DeepSetElectionModel,\n",
    ")\n",
    "\n",
    "device = torch.device(0) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"num_voters_range\": (3, 50),\n",
    "    \"num_candidates_range\": (2, 10),\n",
    "    \"train_dataset_size\": 10_000,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"train_num_epochs\": 200,\n",
    "    \"checkpoint_interval\": 5,\n",
    "    \"val_num_voters\": 75,\n",
    "    \"val_num_candidates\": 15,\n",
    "    \"test_num_voters\": 100,\n",
    "    \"test_num_candidates\": 20,\n",
    "    \"train_iterations_per_epoch\": 1,\n",
    "    \"eval_dataset_size\": 1_000,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"use_monotonicity_loss\": False,\n",
    "    \"monotonicity_loss_batch_size\": 32,\n",
    "    \"voting_rule\": \"nash\",\n",
    "    \"representation\": \"graph\",\n",
    "}\n",
    "\n",
    "\n",
    "def generate_rule_dataset(\n",
    "    dataset_size: int,\n",
    "    num_voters_range: RangeOrValue,\n",
    "    num_candidates_range: RangeOrValue,\n",
    "    dataloader_batch_size: int,\n",
    "    top_k_candidates: int | None,\n",
    "    voting_rule: Literal[\"plurality\", \"borda\", \"copeland\", \"utilitarian\", \"nash\", \"rawlsian\"],\n",
    "    representation: Literal[\"set\", \"graph\"],\n",
    "    seed: int,\n",
    "    recompute: bool = True,\n",
    "):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    dataset_file = os.path.join(\n",
    "        OUTPUT_DIR,\n",
    "        f\"rule_dataset_{dataset_size}_{num_voters_range}_{num_candidates_range}_{representation}_{voting_rule}_{seed}.pt\",\n",
    "    )\n",
    "    if os.path.exists(dataset_file) and not recompute:\n",
    "        with open(dataset_file, \"rb\") as f:\n",
    "            dataset = torch.load(f, weights_only=False)\n",
    "    else:\n",
    "        dataset = []\n",
    "\n",
    "        generated_count = 0\n",
    "        with tqdm(range(dataset_size)) as pbar:\n",
    "            while generated_count < dataset_size:\n",
    "                num_voters = get_value(num_voters_range, rng)\n",
    "                num_candidates = get_value(num_candidates_range, rng)\n",
    "\n",
    "                election_data = generate_synthetic_election(\n",
    "                    num_voters=num_voters, num_candidates=num_candidates, rng=rng\n",
    "                )\n",
    "\n",
    "                match voting_rule:\n",
    "                    case \"plurality\":\n",
    "                        scores = election_data.positional_ballots[0]\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case \"borda\":\n",
    "                        scoring = torch.tensor(\n",
    "                            list(range(num_candidates, 0, -1)), dtype=torch.float32\n",
    "                        )\n",
    "                        scores = scoring @ election_data.positional_ballots\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case \"copeland\":\n",
    "                        scores = election_data.tournament_embedding.sum(dim=1)\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case \"utilitarian\":\n",
    "                        scores = election_data.voter_utilities.sum(dim=0)\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case \"nash\":\n",
    "                        # Use log utilities for stability\n",
    "                        election_data.voter_utilities = election_data.voter_utilities.log()\n",
    "                        scores = election_data.voter_utilities.sum(dim=0)\n",
    "                        # scores = election_data.voter_utilities.prod(dim=0)\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case \"rawlsian\":\n",
    "                        scores = candidate_welfare = election_data.voter_utilities.min(dim=0)[0]\n",
    "                        winners = get_scoring_function_winners(scores)\n",
    "                    case _:\n",
    "                        raise ValueError(\"Unknown voting rule.\")\n",
    "\n",
    "                if winners.max() < 1.0:\n",
    "                    # Tie\n",
    "                    continue\n",
    "\n",
    "                if representation == \"graph\":\n",
    "                    graph = election_data.to_bipartite_graph(\n",
    "                        top_k_candidates, vote_data=\"utility\"\n",
    "                    )\n",
    "                    graph.y = election_data.voter_utilities.sum(dim=0)\n",
    "                    graph.winners = winners\n",
    "                    dataset.append(graph)\n",
    "                elif representation == \"set\":\n",
    "                    pad_shape = get_max(num_candidates_range) - num_candidates\n",
    "                    voter_preferences = election_data.voter_preferences_alt\n",
    "                    voter_preferences = torch.nn.functional.pad(\n",
    "                        voter_preferences, (0, pad_shape, 0, 0)\n",
    "                    )\n",
    "                    winners = torch.nn.functional.pad(winners, (0, pad_shape))\n",
    "                    dataset.append((voter_preferences, winners))\n",
    "\n",
    "                generated_count += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "        with open(dataset_file, \"wb\") as f:\n",
    "            torch.save(dataset, f)\n",
    "\n",
    "    if representation == \"graph\":\n",
    "        dataloader = GraphDataloader(\n",
    "            dataset, batch_size=dataloader_batch_size, shuffle=True\n",
    "        )\n",
    "    elif representation == \"set\":\n",
    "        voter_preferences_list = [x[0] for x in dataset]\n",
    "        winner_list = [x[1] for x in dataset]\n",
    "        set_dataset = SetDataset(voter_preferences_list, winner_list)\n",
    "        dataloader = TorchDataloader(\n",
    "            set_dataset,\n",
    "            batch_size=dataloader_batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=SetDataset.collate_fn,\n",
    "        )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "generate_dataset = partial(\n",
    "    generate_rule_dataset,\n",
    "    voting_rule=config[\"voting_rule\"],\n",
    "    representation=config[\"representation\"],\n",
    "    dataloader_batch_size=config[\"train_batch_size\"],\n",
    "    top_k_candidates=None,\n",
    "    recompute=False,\n",
    ")\n",
    "\n",
    "train_dataloader = generate_dataset(\n",
    "    dataset_size=config[\"train_dataset_size\"],\n",
    "    num_voters_range=config[\"num_voters_range\"],\n",
    "    num_candidates_range=config[\"num_candidates_range\"],\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "val_dataloader = generate_dataset(\n",
    "    dataset_size=config[\"eval_dataset_size\"],\n",
    "    num_voters_range=config[\"val_num_voters\"],\n",
    "    num_candidates_range=config[\"val_num_candidates\"],\n",
    "    seed=16180,\n",
    ")\n",
    "\n",
    "if config[\"representation\"] == \"graph\":\n",
    "    test_num_candidates = config[\"test_num_candidates\"]\n",
    "elif config[\"representation\"] == \"set\":\n",
    "    test_num_candidates = get_max(config[\"num_candidates_range\"])\n",
    "\n",
    "test_dataloader = generate_dataset(\n",
    "    dataset_size=config[\"eval_dataset_size\"],\n",
    "    num_voters_range=config[\"test_num_voters\"],\n",
    "    num_candidates_range=test_num_candidates,\n",
    "    seed=314159,\n",
    ")\n",
    "\n",
    "config[\"train_iterations_per_epoch\"] = min(\n",
    "    config[\"train_iterations_per_epoch\"], len(iter(train_dataloader))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_count: 1022081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yash/Projects/fresh-geometric-governance/geometric_governance/../outputs/graph-election-nash/2025-03-28 17-39-15/wandb/run-20250328_173915-bhsaoz25</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance/runs/bhsaoz25' target=\"_blank\">graph-election-nash</a></strong> to <a href='https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance' target=\"_blank\">https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance/runs/bhsaoz25' target=\"_blank\">https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance/runs/bhsaoz25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▋                                                                                                                                         | 1/200 [00:00<01:04,  3.11it/s, train_rule_loss=1.56, train_accuracy=0.391, val_rule_loss=0.692, val_accuracy=0.866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                       | 2/200 [00:00<01:03,  3.14it/s, train_rule_loss=0.129, train_accuracy=0.961, val_rule_loss=0.111, val_accuracy=0.958]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▊                                                                                                                                        | 4/200 [00:01<01:01,  3.19it/s, train_rule_loss=0.0355, train_accuracy=1, val_rule_loss=0.0408, val_accuracy=0.988]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████████                                                                                                                            | 15/200 [00:04<00:57,  3.22it/s, train_rule_loss=0.0406, train_accuracy=0.992, val_rule_loss=0.0287, val_accuracy=0.989]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████                                                                                                                               | 16/200 [00:04<00:57,  3.19it/s, train_rule_loss=0.0159, train_accuracy=1, val_rule_loss=0.0271, val_accuracy=0.994]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████████████▍                                                                                                                    | 26/200 [00:08<00:54,  3.20it/s, train_rule_loss=0.0275, train_accuracy=0.992, val_rule_loss=0.0179, val_accuracy=0.997]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████████▉                                                                                           | 66/200 [00:20<00:41,  3.23it/s, train_rule_loss=0.00544, train_accuracy=1, val_rule_loss=0.00949, val_accuracy=0.999]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:04<00:00,  3.10it/s, train_rule_loss=0.000685, train_accuracy=1, val_rule_loss=0.0234, val_accuracy=0.994]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>train/monotonicity_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/rule_loss</td><td>▅▆▃▂▃▃▃▄▂▄▄█▂▃▂▂▂▁▁▂▂▃▁▂▂▂▁▁▁▁▁▂▁▁▂▁▁▂▁▁</td></tr><tr><td>train/total_loss</td><td>▆▆▃█▃▃▅▂▃▄▂▃▂▁▃▁▂▃▃▂▂▃▂▂▂▂▂▁▁▂▂▁▁▁▁▁▂▂▁▁</td></tr><tr><td>train/welfare</td><td>▅▆▁▆▆▄▅▃▄▆▅▃▄▂▆▄▇▆▄▃▅▃▆▇▆▆▃▇▆▇▄▄▄▅▆▆▇█▄▄</td></tr><tr><td>val/accuracy</td><td>▃▂▁▄▄▃▆▇▅▃▆▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇█▇██████▇▇█▇▇</td></tr><tr><td>val/rule_loss</td><td>▄█▅▃▅▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁</td></tr><tr><td>val/welfare</td><td>▄▅▅▃▅▃▃▄▆▃▅▆▆▆▄▇▆▇▅█▅▇▇▅▁█▆▂▂▆█▃▆▅▄▅▆▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/accuracy</td><td>1</td></tr><tr><td>train/monotonicity_loss</td><td>0</td></tr><tr><td>train/rule_loss</td><td>0.00068</td></tr><tr><td>train/total_loss</td><td>0.00068</td></tr><tr><td>train/welfare</td><td>-49.51244</td></tr><tr><td>val/accuracy</td><td>0.994</td></tr><tr><td>val/rule_loss</td><td>0.02342</td></tr><tr><td>val/welfare</td><td>-225.17649</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graph-election-nash</strong> at: <a href='https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance/runs/bhsaoz25' target=\"_blank\">https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance/runs/bhsaoz25</a><br> View project at: <a href='https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance' target=\"_blank\">https://wandb.ai/paroxysmisch-university-of-cambridge/geometric-governance</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/yash/Projects/fresh-geometric-governance/geometric_governance/../outputs/graph-election-nash/2025-03-28 17-39-15/wandb/run-20250328_173915-bhsaoz25/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 5\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if config[\"representation\"] == \"graph\":\n",
    "    election_model = MessagePassingElectionModel(\n",
    "        node_emb_dim=256, edge_emb_dim=64, num_layers=4, edge_dim=1\n",
    "    )\n",
    "elif config[\"representation\"] == \"set\":\n",
    "    election_model = DeepSetElectionModel(\n",
    "        get_max(config[\"num_candidates_range\"]), embedding_size=155\n",
    "    )\n",
    "parameter_count = sum(p.numel() for p in election_model.parameters() if p.requires_grad)\n",
    "print(f\"parameter_count: {parameter_count}\")\n",
    "\n",
    "\n",
    "election_model.to(device=device)\n",
    "optim = torch.optim.Adam(election_model.parameters(), lr=config[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim, T_max=config[\"train_num_epochs\"], eta_min=1e-4\n",
    ")\n",
    "experiment_name = f\"{config['representation']}-election-{config['voting_rule']}\"\n",
    "with (\n",
    "    Logger(\n",
    "        experiment_name=experiment_name,\n",
    "        config=config,\n",
    "        mode=\"online\",\n",
    "    ) as logger,\n",
    "    tqdm(range(config[\"train_num_epochs\"])) as pbar,\n",
    "):\n",
    "    best_validation_accuracy: float = 0.0\n",
    "\n",
    "    for epoch in range(config[\"train_num_epochs\"]):\n",
    "        # Train\n",
    "        train_loss = 0\n",
    "        train_rule_loss = 0\n",
    "        train_monotonicity_loss = 0\n",
    "        train_welfare = 0\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        election_model.train()\n",
    "\n",
    "        train_iter = iter(train_dataloader)\n",
    "\n",
    "        for _ in range(config[\"train_iterations_per_epoch\"]):\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # Rule Loss\n",
    "            if config[\"representation\"] == \"graph\":\n",
    "                data = next(train_iter).to(device=device)\n",
    "                data.edge_attr.requires_grad = True\n",
    "                out = election_model(data)\n",
    "                winners = data.winners\n",
    "                rule_loss = -(out * winners).sum() / config[\"train_batch_size\"]\n",
    "            elif config[\"representation\"] == \"set\":\n",
    "                X, index, y = next(train_iter)\n",
    "                X = X.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "                index = index.to(device=device)\n",
    "                out = election_model(X, index=index)\n",
    "                winners = y\n",
    "                rule_loss = torch.nn.functional.cross_entropy(out, winners)\n",
    "\n",
    "            # Monotonicity loss\n",
    "            monotonicity_loss = 0\n",
    "\n",
    "            if config[\"use_monotonicity_loss\"] and config[\"representation\"] == \"graph\":\n",
    "                candidates = data.candidate_idxs.nonzero()\n",
    "                perm = torch.randperm(candidates.size(0))[\n",
    "                    : config[\"monotonicity_loss_batch_size\"]\n",
    "                ]\n",
    "                for i in perm:\n",
    "                    candidate_idx = candidates[i]\n",
    "                    edge_idxs = data.edge_index[1] == candidate_idx\n",
    "                    grad = torch.autograd.grad(\n",
    "                        outputs=out[i], inputs=data.edge_attr, create_graph=True\n",
    "                    )[0]\n",
    "                    monotonicity_loss += torch.where(\n",
    "                        grad[edge_idxs] < 0,\n",
    "                        -grad[edge_idxs],\n",
    "                        torch.zeros_like(grad[edge_idxs]),\n",
    "                    ).mean()\n",
    "            monotonicity_loss /= config[\"monotonicity_loss_batch_size\"]\n",
    "\n",
    "            loss = rule_loss + monotonicity_loss\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                election_model.parameters(), config[\"clip_grad_norm\"]\n",
    "            )\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if config[\"representation\"] == \"graph\":\n",
    "                batch_idxs = data.batch[data.candidate_idxs]\n",
    "                _, predicted = scatter_max(out, batch_idxs)\n",
    "                _, predicted_ground = scatter_max(winners, batch_idxs)\n",
    "            elif config[\"representation\"] == \"set\":\n",
    "                _, predicted = torch.max(out, dim=1)\n",
    "                _, predicted_ground = torch.max(winners, dim=1)\n",
    "\n",
    "            total += predicted_ground.shape[0]\n",
    "            correct += (predicted == predicted_ground).sum().item()\n",
    "            if config[\"representation\"] == \"graph\":\n",
    "                welfare = data.y[predicted].mean()\n",
    "                train_welfare += welfare.item()\n",
    "            train_loss += loss.item()\n",
    "            train_rule_loss += rule_loss.item()\n",
    "            if config[\"use_monotonicity_loss\"]:\n",
    "                train_monotonicity_loss += monotonicity_loss.item()\n",
    "\n",
    "        train_loss /= config[\"train_iterations_per_epoch\"]\n",
    "        train_rule_loss /= config[\"train_iterations_per_epoch\"]\n",
    "        train_monotonicity_loss /= config[\"train_iterations_per_epoch\"]\n",
    "        train_welfare /= config[\"train_iterations_per_epoch\"]\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        if epoch % config[\"checkpoint_interval\"] == 0:\n",
    "            torch.save(\n",
    "                election_model, os.path.join(logger.checkpoint_dir, f\"model_{epoch}.pt\")\n",
    "            )\n",
    "\n",
    "        logger.log(\n",
    "            {\n",
    "                \"train/total_loss\": train_loss,\n",
    "                \"train/rule_loss\": train_rule_loss,\n",
    "                \"train/monotonicity_loss\": train_monotonicity_loss,\n",
    "                \"train/welfare\": train_welfare,\n",
    "                \"train/accuracy\": train_accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        if config[\"representation\"] == \"graph\":\n",
    "            val_welfare = 0\n",
    "            election_model.eval()\n",
    "            total, correct = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for data_ in val_dataloader:\n",
    "                    data = data_.to(device=device)\n",
    "                    out = election_model(data)\n",
    "                    rule_loss = -(out * data.winners).sum() / config[\"train_batch_size\"]\n",
    "                    if config[\"representation\"] == \"graph\":\n",
    "                        batch_idxs = data.batch[data.candidate_idxs]\n",
    "                        _, predicted = scatter_max(out, batch_idxs)\n",
    "                        _, predicted_ground = scatter_max(data.winners, batch_idxs)\n",
    "                    elif config[\"representation\"] == \"set\":\n",
    "                        _, predicted = torch.max(out, dim=1)\n",
    "                        _, predicted_ground = torch.max(data.winners, dim=1)\n",
    "\n",
    "                    total += predicted_ground.shape[0]\n",
    "                    correct += (predicted == predicted_ground).sum().item()\n",
    "\n",
    "                    welfare = data.y[predicted].mean()\n",
    "                    val_loss += rule_loss.item()\n",
    "                    val_welfare += welfare.item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_welfare /= len(val_dataloader)\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "            if val_accuracy > best_validation_accuracy:\n",
    "                print(f\"New best accuracy: {val_accuracy}\")\n",
    "                torch.save(\n",
    "                    election_model,\n",
    "                    os.path.join(logger.checkpoint_dir, \"model_best.pt\"),\n",
    "                )\n",
    "                best_validation_accuracy = val_accuracy\n",
    "\n",
    "            logger.log(\n",
    "                {\n",
    "                    \"val/rule_loss\": val_loss,\n",
    "                    \"val/accuracy\": val_accuracy,\n",
    "                    \"val/welfare\": val_welfare,\n",
    "                }\n",
    "            )\n",
    "        logger.commit()\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            {\n",
    "                \"train_rule_loss\": train_rule_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_rule_loss\": val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "            }\n",
    "        )\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | Accuracy 1.0 | Loss 0.00241581993032014\n"
     ]
    }
   ],
   "source": [
    "if config[\"representation\"] == \"graph\":\n",
    "    election_model = torch.load(\n",
    "        os.path.join(logger.checkpoint_dir, \"model_best.pt\"), weights_only=False\n",
    "    )\n",
    "    election_model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data_ in test_dataloader:\n",
    "            data = data_.to(device=device)\n",
    "            out = election_model(data)\n",
    "            rule_loss = -(out * data.winners).sum() / config[\"train_batch_size\"]\n",
    "            batch_idxs = data.batch[data.candidate_idxs]\n",
    "            _, predicted = scatter_max(out, batch_idxs)\n",
    "            _, predicted_ground = scatter_max(data.winners, batch_idxs)\n",
    "            total += predicted_ground.shape[0]\n",
    "            correct += (predicted == predicted_ground).sum().item()\n",
    "            test_loss += rule_loss.item()\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_accuracy = correct / total\n",
    "\n",
    "    print(f\"Test | Accuracy {test_accuracy} | Loss {test_loss}\")\n",
    "elif config[\"representation\"] == \"set\":\n",
    "    election_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, index, y in test_dataloader:\n",
    "            X = X.to(device)\n",
    "            index = index.to(device)\n",
    "            y = y.to(device)\n",
    "            p_y = election_model(X, index)\n",
    "            _, predicted = torch.max(p_y, dim=1)\n",
    "            _, predicted_ground = torch.max(y, dim=1)\n",
    "            total += y.shape[0]\n",
    "            correct += (predicted == predicted_ground).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   3,   25,   46,   62,   85,  117,  133,  148,  173,  189,  204,  230,\n",
       "         246,  272,  285,  314,  328,  347,  372,  383,  400,  429,  454,  471,\n",
       "         494,  519,  522,  550,  565,  593,  611,  620,  642,  664,  685,  716,\n",
       "         727,  759,  769,  792,  803,  828,  850,  869,  892,  914,  937,  951,\n",
       "         973,  997, 1015, 1034, 1051, 1060, 1092, 1108, 1125, 1154, 1172, 1196,\n",
       "        1200, 1228, 1249, 1260, 1291, 1302, 1329, 1351, 1369, 1385, 1405, 1428,\n",
       "        1444, 1478, 1495, 1506, 1533, 1549, 1560, 1582, 1608, 1632, 1657, 1676,\n",
       "        1697, 1711, 1738, 1740, 1769, 1788, 1819, 1832, 1849, 1861, 1886, 1917,\n",
       "        1936, 1942, 1965, 1981, 2018, 2029, 2047, 2069], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   3,   25,   46,   62,   85,  117,  133,  148,  173,  189,  204,  230,\n",
       "         246,  272,  285,  314,  328,  347,  372,  383,  400,  429,  454,  471,\n",
       "         494,  519,  522,  550,  565,  593,  611,  620,  642,  664,  685,  716,\n",
       "         727,  759,  769,  792,  803,  828,  850,  869,  892,  914,  937,  951,\n",
       "         973,  997, 1015, 1034, 1051, 1060, 1092, 1108, 1125, 1154, 1172, 1196,\n",
       "        1200, 1228, 1249, 1260, 1291, 1302, 1329, 1351, 1369, 1385, 1405, 1428,\n",
       "        1444, 1478, 1495, 1506, 1533, 1549, 1560, 1582, 1608, 1632, 1657, 1676,\n",
       "        1697, 1711, 1738, 1740, 1769, 1788, 1819, 1832, 1849, 1861, 1886, 1917,\n",
       "        1936, 1942, 1965, 1981, 2018, 2029, 2047, 2069], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -294.8145, -1092.3062,  -696.4897,  ...,  -237.2563,   -19.7446,\n",
       "        -1796.7393], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
