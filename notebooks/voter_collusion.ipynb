{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning plurality voting with DeepSets\n",
    "\n",
    "## Dataset construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.nn import MLP, DeepSetsAggregation, conv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from geometric_governance.util import RangeOrValue, get_value\n",
    "from geometric_governance.data import generate_synthetic_election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VOTERS_RANGE = (3, 10)\n",
    "NUM_COLLUDERS_RANGE = (0, 4)\n",
    "NUM_CANDIDATES = 5\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TRAIN_NUM_EPOCHS = 1_000\n",
    "NUM_COLLUDE_STEPS = 1\n",
    "NUM_DISCRIMINATOR_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
      "        [1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "def fully_connected_directed_edge_index(n):\n",
    "    row, col = torch.meshgrid(torch.arange(n), torch.arange(n), indexing='ij')\n",
    "    edge_index = torch.stack([row.flatten(), col.flatten()], dim=0)\n",
    "    return edge_index[:, edge_index[0] != edge_index[1]]  # Remove self-loops\n",
    "\n",
    "print(fully_connected_directed_edge_index(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollusionModel(nn.Module):\n",
    "    def __init__(self, num_candidates: int, embedding_size: int = 128):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.fc1 = nn.Linear(num_candidates, embedding_size)\n",
    "        self.convs = nn.ModuleList([conv.GATv2Conv(in_channels=(2 * embedding_size), out_channels=(embedding_size)) for _ in range(5)])\n",
    "        self.fc2 = nn.Linear(embedding_size, num_candidates)\n",
    "\n",
    "    def forward(self, x):\n",
    "        index = fully_connected_directed_edge_index(x.size(-2))\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        for conv_layer in self.convs:\n",
    "            # Use Randomized Normal Features to disambiguate voters\n",
    "            rnf = torch.normal(mean=torch.zeros_like(x), std=1.)\n",
    "            x = torch.concat([x, rnf], dim=-1)\n",
    "\n",
    "            x = conv_layer(x, index)\n",
    "            \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = F.softmax(x, dim=-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorModel(nn.Module):\n",
    "    def __init__(self, num_candidates: int, embedding_size: int = 128):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.fc1 = nn.Linear(num_candidates, embedding_size)\n",
    "        self.convs = nn.ModuleList([conv.GATv2Conv(in_channels=(2 * embedding_size), out_channels=(embedding_size)) for _ in range(3)])\n",
    "        self.fc2 = nn.Linear(embedding_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        index = fully_connected_directed_edge_index(x.size(-2))\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        for conv_layer in self.convs:\n",
    "            # Use Randomized Normal Features to disambiguate voters\n",
    "            rnf = torch.normal(mean=torch.zeros(x.size(-2), self.embedding_size), std=1.)\n",
    "            x = torch.concat([x, rnf], dim=-1)\n",
    "            \n",
    "            x = conv_layer(x, index)\n",
    "\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        x = x.view(-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "collusion_model = CollusionModel(NUM_CANDIDATES)\n",
    "collusion_model.train()\n",
    "collusion_optim = torch.optim.Adam(collusion_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = DiscriminatorModel(NUM_CANDIDATES)\n",
    "discriminator_model.train()\n",
    "discriminator_optim = torch.optim.Adam(discriminator_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 132.49it/s, collusion_loss=tensor(1.1485, grad_fn=<DivBackward1>), discriminator_loss=tensor(0.0085, grad_fn=<BinaryCrossEntropyBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "epochs = tqdm(range(TRAIN_NUM_EPOCHS))\n",
    "for epoch in epochs:\n",
    "    for _ in range(NUM_COLLUDE_STEPS):\n",
    "        num_voters = get_value(NUM_VOTERS_RANGE, rng)\n",
    "        num_colluders = get_value(NUM_COLLUDERS_RANGE, rng)\n",
    "        voter_utilities = rng.dirichlet(\n",
    "            alpha=(1.,) * NUM_CANDIDATES, size=(num_voters + 1)\n",
    "        )\n",
    "        # Duplicate the last candidate's data to generate colluding voters' data\n",
    "        # so that all colluding candidates share the same utility\n",
    "        collusion_utility = voter_utilities[-1][None, :]\n",
    "        collusion_candidate = np.argmax(collusion_utility)\n",
    "        collusion_utilities = np.tile(collusion_utility, (num_colluders, 1))\n",
    "        collusion_utilities = torch.from_numpy(collusion_utilities).float()\n",
    "    \n",
    "        # Colluders cast their vote jointly (by adjusting the utilities)\n",
    "        collusion_utilities = collusion_model(collusion_utilities)\n",
    "    \n",
    "        # Assimilate votes, removing those thought to be fake by the discriminator\n",
    "        assimiliated_utilities = torch.cat([torch.from_numpy(voter_utilities[:-1]).float(), collusion_utilities])\n",
    "        possibly_fake = 1. - discriminator_model(assimiliated_utilities).detach()\n",
    "        assimiliated_utilities = assimiliated_utilities * possibly_fake.unsqueeze(-1)\n",
    "    \n",
    "        # Plurality voting\n",
    "        election_result = F.softmax(torch.sum(assimiliated_utilities, dim=-2), dim=-1)\n",
    "    \n",
    "        # The colluders' loss is how close they can get to getting their chosen candidate to win the election/lottery\n",
    "        ideal_result = torch.zeros_like(election_result)\n",
    "        ideal_result[collusion_candidate] = 1.\n",
    "    \n",
    "        collusion_optim.zero_grad()\n",
    "        collusion_loss = F.cross_entropy(election_result, ideal_result)\n",
    "        collusion_loss.backward()\n",
    "        collusion_optim.step()\n",
    "\n",
    "    for _ in range(NUM_DISCRIMINATOR_STEPS):\n",
    "        num_voters_discrim = get_value(NUM_VOTERS_RANGE, rng)\n",
    "        num_colluders_discrim = get_value(NUM_COLLUDERS_RANGE, rng)\n",
    "        voter_utilities_discrim = rng.dirichlet(\n",
    "            alpha=(1.,) * NUM_CANDIDATES, size=(num_voters_discrim + 1)\n",
    "        )\n",
    "        # Duplicate the last candidate's data to generate colluding voters' data\n",
    "        # so that all colluding candidates share the same utility\n",
    "        collusion_utility_discrim = voter_utilities_discrim[-1][None, :]\n",
    "        collusion_utilities_discrim = np.tile(collusion_utility_discrim, (num_colluders_discrim, 1))\n",
    "        collusion_utilities_discrim = torch.from_numpy(collusion_utilities_discrim).float()\n",
    "        \n",
    "        # Discriminator tries to distinguish the colluders' voting patterns\n",
    "        # Regenerate colluders' output\n",
    "        collusion_utilities_discrim = collusion_model(collusion_utilities_discrim).detach()\n",
    "        assimiliated_utilities_discrim = torch.cat([torch.from_numpy(voter_utilities_discrim[:-1]).float(), collusion_utilities_discrim])\n",
    "    \n",
    "        discriminator_output = discriminator_model(assimiliated_utilities_discrim)\n",
    "        colluders_mask = torch.cat([torch.zeros(num_voters_discrim), torch.ones(num_colluders_discrim)])\n",
    "        discriminator_optim.zero_grad()\n",
    "        discriminator_loss = F.binary_cross_entropy(discriminator_output, colluders_mask)\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optim.step()\n",
    "\n",
    "    epochs.set_postfix({\"collusion_loss\": collusion_loss, \"discriminator_loss\": discriminator_loss})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02813386, 0.06883993, 0.00408478, 0.56029761, 0.33864382]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collusion_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collusion_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7189, 0.7173, 0.7182, 0.7210, 0.7177, 0.7181, 0.7139, 0.7219])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possibly_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0540, 0.0500, 0.1309, 0.6958, 0.0693], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0085, 0.0084, 0.0085, 0.0084, 0.0086], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colluders_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1059, 0.0349, 0.1458, 0.5873, 0.1261],\n",
       "        [0.0092, 0.0398, 0.5392, 0.0300, 0.3818],\n",
       "        [0.6413, 0.0779, 0.0100, 0.0861, 0.1846],\n",
       "        [0.1527, 0.3545, 0.1766, 0.1637, 0.1524],\n",
       "        [0.0429, 0.0893, 0.2626, 0.3948, 0.2103]])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assimiliated_utilities_discrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
